{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # %%\n",
    "# # https://github.com/meta-llama/llama-models/blob/main/README.md\n",
    "\n",
    "# # %%\n",
    "# ! pip install llama-toolchain\n",
    "\n",
    "# # %%\n",
    "# ! llama model list\n",
    "\n",
    "# # %%\n",
    "# ! llama download --source meta --model-id Meta-Llama3.1-8B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! cd modules/musecoco/1-text2attribute_model ;\\\n",
    "# cat data/predict.json ;\\\n",
    "# bash predict.sh ;\\\n",
    "# python stage2_pre.py ;\\\n",
    "# mv infer_test.bin ../2-attribute2music_model/data/infer_input\n",
    "\n",
    "# ! cd /workspace/Chat_Midi/muzic/musecoco/2-attribute2music_model ;\\\n",
    "# bash interactive_1billion.sh 0 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! cd muzic/musecoco/evaluation ;\\\n",
    "# python eval_acc_v3.py --root /workspace/Chat_Midi/muzic/musecoco/2-attribute2music_model/generation/0505/linear_mask-1billion-checkpoint_2_280000/infer_test/topk15-t1.0-ngram0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-11 02:01:38 | WARNING | src.control.musecoco.text2attribute_model.main | Process rank: -1, device: cuda:0, n_gpu: 2distributed training: False, 16-bits training: False\n",
      "2024-09-11 02:01:38 | INFO | src.control.musecoco.text2attribute_model.main | Training/evaluation parameters TrainingArguments(\n",
      "_n_gpu=2,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "auto_find_batch_size=False,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "data_seed=None,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "ddp_timeout=1800,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=False,\n",
      "do_predict=True,\n",
      "do_train=False,\n",
      "eval_accumulation_steps=None,\n",
      "eval_delay=0,\n",
      "eval_steps=None,\n",
      "evaluation_strategy=no,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "fsdp=[],\n",
      "fsdp_min_num_params=0,\n",
      "fsdp_transformer_layer_cls_to_wrap=None,\n",
      "full_determinism=False,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_private_repo=False,\n",
      "hub_strategy=every_save,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "include_inputs_for_metrics=False,\n",
      "jit_mode_eval=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=5e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=passive,\n",
      "log_level_replica=passive,\n",
      "log_on_each_node=True,\n",
      "logging_dir=storage/tmp/runs/Sep11_02-01-38_2742e12a356b,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=500,\n",
      "logging_strategy=steps,\n",
      "lr_scheduler_type=linear,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3.0,\n",
      "optim=adamw_hf,\n",
      "optim_args=None,\n",
      "output_dir=storage/tmp,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=8,\n",
      "per_device_train_batch_size=8,\n",
      "prediction_loss_only=False,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "ray_scope=last,\n",
      "remove_unused_columns=True,\n",
      "report_to=['tensorboard', 'wandb'],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=storage/tmp,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=steps,\n",
      "save_total_limit=None,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "tf32=None,\n",
      "torch_compile=False,\n",
      "torch_compile_backend=None,\n",
      "torch_compile_mode=None,\n",
      "torchdynamo=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_ipex=False,\n",
      "use_legacy_prediction_loop=False,\n",
      "use_mps_device=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "2024-09-11 02:01:38 | INFO | src.control.musecoco.text2attribute_model.main | load a local file for test: storage/input/predict.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/MuseCoco/lib/python3.8/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "[INFO|configuration_utils.py:660] 2024-09-11 02:01:38,854 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--IreneXu--MuseCoco_text2attribute/snapshots/7ae4925d3b78107069e16d24ee3755aa26be944e/config.json\n",
      "[INFO|configuration_utils.py:712] 2024-09-11 02:01:38,855 >> Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-large-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForAttributModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.26.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1802] 2024-09-11 02:01:39,294 >> loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--IreneXu--MuseCoco_text2attribute/snapshots/7ae4925d3b78107069e16d24ee3755aa26be944e/vocab.txt\n",
      "[INFO|tokenization_utils_base.py:1802] 2024-09-11 02:01:39,295 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--IreneXu--MuseCoco_text2attribute/snapshots/7ae4925d3b78107069e16d24ee3755aa26be944e/tokenizer.json\n",
      "[INFO|tokenization_utils_base.py:1802] 2024-09-11 02:01:39,295 >> loading file added_tokens.json from cache at None\n",
      "[INFO|tokenization_utils_base.py:1802] 2024-09-11 02:01:39,295 >> loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--IreneXu--MuseCoco_text2attribute/snapshots/7ae4925d3b78107069e16d24ee3755aa26be944e/special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:1802] 2024-09-11 02:01:39,296 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--IreneXu--MuseCoco_text2attribute/snapshots/7ae4925d3b78107069e16d24ee3755aa26be944e/tokenizer_config.json\n",
      "[INFO|modeling_utils.py:2275] 2024-09-11 02:01:39,308 >> loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--IreneXu--MuseCoco_text2attribute/snapshots/7ae4925d3b78107069e16d24ee3755aa26be944e/pytorch_model.bin\n",
      "[INFO|modeling_utils.py:2857] 2024-09-11 02:01:43,995 >> All model checkpoint weights were used when initializing BertForAttributModel.\n",
      "\n",
      "[INFO|modeling_utils.py:2865] 2024-09-11 02:01:43,996 >> All the weights of BertForAttributModel were initialized from the model checkpoint at IreneXu/MuseCoco_text2attribute.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForAttributModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-11 02:01:47 | INFO | fairseq_cli.interactive | Namespace(add_bos_token=False, all_gather_list_size=16384, batch_size=2, batch_size_valid=2, beam=1, bf16=False, bpe=None, broadcast_buffers=False, bucket_cap_mb=25, buffer_size=2, checkpoint_shard_count=1, checkpoint_suffix='', command_embed_dim=None, command_mask_prob=0.4, command_path=None, constraints=None, cpu=False, criterion='cross_entropy', ctrl_command_path='storage/tmp/infer_test.bin', curriculum=0, data='src/control/musecoco/attribute2music_model/data/truncated_2560/data-bin', data_buffer_size=10, dataset_impl=None, ddp_backend='c10d', decoding_format=None, device_id=0, disable_validation=False, distributed_backend='nccl', distributed_init_method=None, distributed_no_spawn=False, distributed_port=-1, distributed_rank=0, distributed_world_size=1, distributed_wrapper='DDP', diverse_beam_groups=-1, diverse_beam_strength=0.5, diversity_rate=-1.0, empty_cache_freq=0, end=100, fast_stat_sync=False, find_unused_parameters=False, fix_batches_to_gpus=False, fixed_validation_seed=None, force_anneal=None, fp16=False, fp16_init_scale=128, fp16_no_flatten_grads=False, fp16_scale_tolerance=0.0, fp16_scale_window=None, future_target=False, gen_subset='test', input='-', is_inference=False, iter_decode_eos_penalty=0.0, iter_decode_force_max_iter=False, iter_decode_max_iter=10, iter_decode_with_beam=1, iter_decode_with_external_reranker=False, lenpen=1, lm_path=None, lm_weight=0.0, localsgd_frequency=3, log_format=None, log_interval=100, lr_scheduler='fixed', lr_shrink=0.1, match_source_len=False, max_len_a=0, max_len_b=2560, max_target_positions=None, max_tokens=None, max_tokens_valid=None, memory_efficient_bf16=False, memory_efficient_fp16=False, min_len=512.0, min_loss_scale=0.0001, model_overrides='{}', model_parallel_size=1, nbest=1, need_num=2, no_beamable_mm=False, no_early_stop=False, no_progress_bar=False, no_repeat_ngram_size=0, no_seed_provided=False, nprocs_per_node=2, num_shards=1, num_workers=1, optimizer=None, output_dictionary_size=-1, padding_to_max_length=0, past_target=False, path='src/control/musecoco/attribute2music_model/checkpoints/linear_mask-1billion/checkpoint_2_280000.pt', pipeline_balance=None, pipeline_checkpoint='never', pipeline_chunks=0, pipeline_decoder_balance=None, pipeline_decoder_devices=None, pipeline_devices=None, pipeline_encoder_balance=None, pipeline_encoder_devices=None, pipeline_model_parallel=False, prefix_size=0, print_alignment=False, print_step=False, profile=False, quantization_config_path=None, quiet=False, remove_bpe=None, replace_unk=None, required_batch_size_multiple=8, required_seq_len_multiple=1, results_path=None, retain_dropout=False, retain_dropout_modules=None, retain_iter_history=False, sacrebleu=False, sample_break_mode='none', sampling=True, sampling_topk=15, sampling_topp=-1.0, save_root='storage/generation/0505/linear_mask-1billion-checkpoint_2_280000/topk15-t1.0-ngram0', score_reference=False, scoring='bleu', seed=1, self_target=False, shard_id=0, shorten_data_split_list='', shorten_method='none', skip_invalid_size_inputs_valid_test=False, slowmo_algorithm='LocalSGD', slowmo_momentum=None, start=0, task='language_modeling_control', temperature=1.0, tensorboard_logdir=None, threshold_loss_scale=None, tokenizer=None, tokens_per_sample=1024, tpu=False, train_subset='train', truncated_length=5868, unkpen=0, unnormalized=False, use_gold_labels=0, user_dir=None, valid_subset='valid', validate_after_updates=0, validate_interval=1, validate_interval_updates=0, warmup_updates=0, zero_sharding='none')\n",
      "2024-09-11 02:01:47 | INFO | fairseq.tasks.language_modeling | dictionary: 1253 types\n",
      "2024-09-11 02:01:47 | INFO | fairseq_cli.interactive | loading model(s) from src/control/musecoco/attribute2music_model/checkpoints/linear_mask-1billion/checkpoint_2_280000.pt\n",
      "2024-09-11 02:02:42 | INFO | fairseq_cli.interactive | Sentence buffer size: 2\n",
      "2024-09-11 02:02:42 | INFO | fairseq_cli.interactive | NOTE: hypothesis and token scores are output in base 2\n",
      "2024-09-11 02:02:42 | INFO | fairseq_cli.interactive | Type the input sentence and press return:\n"
     ]
    }
   ],
   "source": [
    "text2attribute_predictor = init_text2attribute()\n",
    "attribute2midi_predictor = init_attribute2midi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/MuseCoco/lib/python3.8/site-packages/datasets/load.py:2566: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'token=<use_auth_token>' instead.\n",
      "  warnings.warn(\n",
      "Using custom data configuration default-6c07d90dc18a6c34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-11 02:03:20 | INFO | datasets.builder | Using custom data configuration default-6c07d90dc18a6c34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Dataset Infos from /root/miniconda3/envs/MuseCoco/lib/python3.8/site-packages/datasets/packaged_modules/json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-11 02:03:20 | INFO | datasets.info | Loading Dataset Infos from /root/miniconda3/envs/MuseCoco/lib/python3.8/site-packages/datasets/packaged_modules/json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Overwrite dataset info from restored data version if exists.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-11 02:03:20 | INFO | datasets.builder | Overwrite dataset info from restored data version if exists.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Dataset info from /root/.cache/huggingface/datasets/json/default-6c07d90dc18a6c34/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-11 02:03:20 | INFO | datasets.info | Loading Dataset info from /root/.cache/huggingface/datasets/json/default-6c07d90dc18a6c34/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset json (/root/.cache/huggingface/datasets/json/default-6c07d90dc18a6c34/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-11 02:03:20 | INFO | datasets.builder | Found cached dataset json (/root/.cache/huggingface/datasets/json/default-6c07d90dc18a6c34/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Dataset info from /root/.cache/huggingface/datasets/json/default-6c07d90dc18a6c34/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-11 02:03:20 | INFO | datasets.info | Loading Dataset info from /root/.cache/huggingface/datasets/json/default-6c07d90dc18a6c34/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1293e84c4ad04064b0c6a28982377bfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset:   0%|          | 0/1 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Caching processed dataset at /root/.cache/huggingface/datasets/json/default-6c07d90dc18a6c34/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-a427485d756364b6.arrow\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-09-11 02:03:23 | INFO | datasets.arrow_dataset | Caching processed dataset at /root/.cache/huggingface/datasets/json/default-6c07d90dc18a6c34/0.0.0/f4e89e8750d5d5ffbef2c078bf0ddfedef29dc2faff52a6255cf513c05eb1092/cache-a427485d756364b6.arrow\n",
      "2024-09-11 02:03:23 | INFO | src.control.musecoco.text2attribute_model.main | *** Predict ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO|trainer.py:710] 2024-09-11 02:03:23,025 >> The following columns in the test set don't have a corresponding argument in `BertForAttributModel.forward` and have been ignored: text. If text are not expected by `BertForAttributModel.forward`,  you can safely ignore this message.\n",
      "/root/miniconda3/envs/MuseCoco/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:30: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 0 which\n",
      "    has less than 75% of the memory or cores of GPU 1. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "[INFO|trainer.py:2964] 2024-09-11 02:03:23,028 >> ***** Running Prediction *****\n",
      "[INFO|trainer.py:2966] 2024-09-11 02:03:23,029 >>   Num examples = 1\n",
      "[INFO|trainer.py:2969] 2024-09-11 02:03:23,029 >>   Batch size = 16\n",
      "/root/miniconda3/envs/MuseCoco/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text2attribute_predictor.predict()\n",
    "prepare_stage2()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starts to generate 0 to 1 of 2 samples in 2 batch steps!\n",
      "2024-09-11 02:03:23 | INFO | src.control.musecoco.attribute2music_model.linear_mask.A2M_task_new | Using max_positions limit (100000) for unknown\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/Chat_Midi/ChatPiano/modules/musecoco-text2midi-service/src/control/musecoco/attribute2music_model/linear_mask/command_seq_generator.py:657: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
      "  unfin_idx = idx // beam_size\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch:0 save_id:0 over with length 940; Average translation time:45.81053590774536 seconds; Remi seq length: 876; Batch size:2;                             Translation shape:2.\n",
      "batch:0 save_id:1 over with length 769; Average translation time:45.81053590774536 seconds; Remi seq length: 705; Batch size:2;                             Translation shape:2.\n"
     ]
    }
   ],
   "source": [
    "attribute2midi_predictor.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MuseCoco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
